{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### carica dataset LDO 20-21 ############################ \n",
    "\n",
    "dataLDO2020 = pd.read_excel('/home/a.renda/to_move/LDO/filtrato_per_keyword/20-21_LDO_26K/LDO_20200101_20210101 pulito.ods', engine='odf')\n",
    "dataLDO2021=pd.read_excel('/home/a.renda/to_move/LDO/filtrato_per_keyword/20-21_LDO_26K/LDO_20210101_20220101 pulito.ods', engine='odf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra le righe che non contengono numeri (escludendo anche i NaN)\n",
    "dataLDO2021 = dataLDO2021[dataLDO2021['nosologico'].astype(str).str.contains(r'\\d')]\n",
    "#rimosse 212 righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nColumns LDO 20-21:\", dataLDO2020.columns)\n",
    "print(\"\\nColumns LDO 21-22:\", dataLDO2021.columns)\n",
    "print(\"\\nShape LDO 20-21:\", dataLDO2020.shape)\n",
    "print(\"\\nShape LDO 21-22:\", dataLDO2021.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### carica database filtrato ################\n",
    "\n",
    "databaseFiltrato=pd.read_csv('/home/a.renda/to_move/LDO/labeled/20-21_341/DatabaseFiltrato.csv', sep=';')\n",
    "print(databaseFiltrato.shape)\n",
    "print(databaseFiltrato.columns) # la prima colonna è solo un contatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra le righe che non contengono numeri (escludendo anche i NaN)\n",
    "databaseFiltrato = databaseFiltrato[databaseFiltrato['nosologico'].astype(str).str.contains(r'\\d')]\n",
    "\n",
    "#tolte 5 righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ filtra ldo 2020 ######################\n",
    "\n",
    "# Converti la colonna 'nosologico' del secondo dataset in int\n",
    "databaseFiltrato['nosologico'] = pd.to_numeric(databaseFiltrato['nosologico'], errors='coerce')\n",
    "\n",
    "# Trova i nosologici comuni\n",
    "comuni2020 = dataLDO2020['nosologico'].isin(databaseFiltrato['nosologico'])\n",
    "\n",
    "# Filtra il primo dataset\n",
    "dataset_filtrato2020 = dataLDO2020[comuni2020]\n",
    "print(dataset_filtrato2020.columns)\n",
    "print(dataset_filtrato2020.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ filtra ldo 2021 ######################\n",
    "\n",
    "# Trova i nosologici comuni\n",
    "comuni2021 = dataLDO2021['nosologico'].isin(databaseFiltrato['nosologico'])\n",
    "\n",
    "# Filtra il primo dataset\n",
    "dataset_filtrato2021 = dataLDO2021[comuni2021]\n",
    "print(dataset_filtrato2021.columns)\n",
    "print(dataset_filtrato2021.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## merge ldo2020 e ldo 2021 filtrati ###################################\n",
    "\n",
    "merged_dataset = pd.concat([dataset_filtrato2020, dataset_filtrato2021], ignore_index=True) # non ci sono duplicati tra i due dataset \n",
    "\n",
    "# Risultato finale\n",
    "print(\"\\nColumns merged dataset:\",merged_dataset.columns)\n",
    "print(\"\\nShape merged dataset:\",merged_dataset.shape)\n",
    "print(merged_dataset['testo'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## carica dataset con nosologici positivi #####################\n",
    "\n",
    "Positivi= pd.read_excel('/home/a.renda/to_move/LDO/labeled/20-21_341/NosologiciPositivi_341.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### aggiungere la colonna positivi #########################################\n",
    "\n",
    "# Convertire la colonna 'Nosologico' in numerico nel dataset NosologiciPositivi\n",
    "nosologici_positivi = pd.to_numeric(Positivi['NosologiciPositivi'], errors='coerce').dropna()\n",
    "\n",
    "# Creare la colonna 'positivi' nel DataFrame merged_dataset\n",
    "merged_dataset['positivi'] = merged_dataset['nosologico'].isin(nosologici_positivi).astype(int)\n",
    "\n",
    "\n",
    "# Contare quanti 1 e quanti 0 ci sono nella colonna 'positivi'\n",
    "count_positivi = merged_dataset['positivi'].value_counts()\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"\\nConteggio dei valori nella colonna 'positivi':\")\n",
    "print(f\"Numero di 1 (positivi): {count_positivi.get(1, 0)}\")\n",
    "print(f\"Numero di 0 (non positivi): {count_positivi.get(0, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unire parole e numeri in 'reparto' rimuovendo lo spazio e sostituendo con un trattino\n",
    "merged_dataset['reparto'] = merged_dataset['reparto'].str.replace(r'(\\w) (\\d)', r'\\1-\\2', regex=True)\n",
    "\n",
    "# Visualizza i risultati\n",
    "print(merged_dataset['reparto'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### pulisci il testo: risoluzione di errori di codifica, sostituzione caratteri speciali #######################\n",
    "import ftfy\n",
    "\n",
    "# Applica ftfy.fix_text() a tutte le colonne di testo nel dataset, gestendo i valori non testuali\n",
    "for col in merged_dataset.select_dtypes(include='object').columns:\n",
    "    merged_dataset[col] = merged_dataset[col].apply(lambda x: ftfy.fix_text(x) if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Crea testo combinato con tutte le colonne di testo #####################################\n",
    "\n",
    "# Seleziona le colonne di testo specificate\n",
    "colonne_testo = ['testo', 'motivo_ricovero', 'anamnesi', 'esameobiettivo',\n",
    "                  'terapiafarmaingresso', 'decorso', 'laboratorio', 'interventi',\n",
    "                  'followup', 'terapie2', 'terapie3', 'esami', 'reparto']\n",
    "\n",
    "# Crea un testo combinato ignorando i NaN\n",
    "merged_dataset['testo_combinato'] = merged_dataset[colonne_testo].apply(\n",
    "    lambda row: ' '.join(\n",
    "        [str(row[col]) for col in colonne_testo if not pd.isna(row[col])]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Stampa le prime righe per vedere il risultato\n",
    "print(merged_dataset['testo_combinato'].head())\n",
    "print(merged_dataset['testo_combinato'][0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### MEDIA NUMERO DI PAROLE NELLE COLONNE ###########################\n",
    "\n",
    "# Funzione per calcolare il numero di parole\n",
    "def count_words(text):\n",
    "    if isinstance(text, str):  # Verifica se il testo è una stringa\n",
    "        return len(text.split())  # Conta le parole\n",
    "    elif isinstance(text, (int, float)):  # Se è un numero\n",
    "        return 1  # Considera il numero come una parola\n",
    "    return 0  # Restituisce 0 se non è una stringa o un numero\n",
    "\n",
    "\n",
    "# Calcola la lunghezza media in parole per ciascuna colonna di testo\n",
    "for colonna in colonne_testo:\n",
    "    word_counts = merged_dataset[colonna].apply(count_words)  # Conta le parole in ogni stringa\n",
    "    average_word_count = word_counts.mean()  # Calcola la lunghezza media\n",
    "    print(f\"Lunghezza media della colonna '{colonna}' in parole: {average_word_count:.2f}\")\n",
    "\n",
    "# Calcola la lunghezza media in parole della colonna di testo combinato\n",
    "word_counts_combined = merged_dataset['testo_combinato'].apply(count_words)  # Conta le parole in ogni stringa\n",
    "average_word_count_combined = word_counts_combined.mean()  # Calcola la lunghezza media\n",
    "print(f\"Lunghezza media della colonna 'testo_combinato' in parole: {average_word_count_combined:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# ISTOGRAMMA LUNGHEZZA TESTO COMBINATO  ############################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcola la lunghezza del testo combinato\n",
    "word_counts_combined = merged_dataset['testo_combinato'].apply(count_words)\n",
    "\n",
    "# Calcola i valori minimi e massimi\n",
    "lunghezza_min = word_counts_combined.min()\n",
    "lunghezza_max = word_counts_combined.max()\n",
    "\n",
    "# Definisce il numero di bin\n",
    "num_bin = 10\n",
    "\n",
    "# Calcola la larghezza delle bin\n",
    "bin_width = (lunghezza_max - lunghezza_min) / num_bin\n",
    "\n",
    "# Crea una lista di bin\n",
    "bins = [lunghezza_min + i * bin_width for i in range(num_bin + 1)]\n",
    "\n",
    "# Crea la figura più larga\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Calcola l'istogramma e i valori delle altezze (n) e dei bin\n",
    "n, bins, patches = plt.hist(\n",
    "    word_counts_combined,  # Usa i conteggi delle parole già calcolati\n",
    "    bins=bins,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Applica la scala logaritmica sull'asse y\n",
    "plt.yscale('log')\n",
    "\n",
    "# Calcola e aggiungi la linea della lunghezza media del testo combinato\n",
    "average_word_count_combined = word_counts_combined.mean()  # Questo ora è un valore scalare\n",
    "plt.axvline(x=average_word_count_combined, color='red', linestyle='--', label='Lunghezza media testo combinato')\n",
    "\n",
    "# Aggiunge il titolo e le etichette degli assi\n",
    "plt.title('Distribuzione della lunghezza dei testi su 10 intervalli di parole')\n",
    "plt.xlabel('Intervalli di parole')\n",
    "plt.ylabel('Numero di testi')\n",
    "\n",
    "# Mostra le etichette delle bin\n",
    "plt.xticks(bins)\n",
    "\n",
    "# Aggiunge una label con il valore sopra ogni barra\n",
    "for i in range(len(n)):\n",
    "    plt.text(bins[i] + bin_width / 2, n[i], str(int(n[i])), ha='center', va='bottom')\n",
    "\n",
    "# Mostra la legenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n",
    "\n",
    "# Stampa i valori minimi e massimi del testo combinato\n",
    "print(f\"Lunghezza massima testo_combinato (in parole): {lunghezza_max}\")\n",
    "print(f\"Lunghezza minima testo_combinato (in parole): {lunghezza_min}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# DIMENSIONE VOCABOLARIO ###########################\n",
    "\n",
    "# Calcola il vocabolario dalla colonna 'testo_combinato_preprocessed'\n",
    "vocab_set = set()\n",
    "for testo in merged_dataset['testo_combinato']:\n",
    "    if isinstance(testo, str):  # Assicurati che il testo non sia NaN\n",
    "        vocab_set.update(testo.split())\n",
    "\n",
    "# Calcola la dimensione del vocabolario\n",
    "vocabolario_dimensione = len(vocab_set)\n",
    "print(f\"Dimensione del vocabolario: {vocabolario_dimensione}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## PRE-PROCESSING VECCHIO ##########################\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Carica il modello SpaCy per l'italiano\n",
    "nlp = spacy.load(\"it_core_news_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Funzione per pulire i token\n",
    "def clean_token(token):\n",
    "    # Rimuove qualsiasi carattere che non sia una lettera o un numero\n",
    "    cleaned_token = re.sub(r'[^a-zA-Z0-9]', '', token)  \n",
    "\n",
    "    # Scarta il token se è composto solo da un carattere o solo da un singolo numero\n",
    "    return '' if len(cleaned_token) == 1 else cleaned_token\n",
    "\n",
    "# Funzione per tokenizzare e preprocessare\n",
    "def preprocess_text(row):\n",
    "    if not isinstance(row, str):  # Verifica che row sia una stringa\n",
    "        return \"\"  # Restituisce una stringa vuota se non è valida (ovvero quando vede un nan restiruisce una stringa vuota)\n",
    "    \n",
    "    # Rimuove date nel formato 'dd/mm/yyyy' e 'dd/mm/yy'\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', '', row)\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}', '', row)  # Rimuove numeri separati da /\n",
    "\n",
    "    # Tokenizza il testo con SpaCy\n",
    "    doc = nlp(row)\n",
    "    \n",
    "    # Filtra stopwords e punteggiatura\n",
    "    tokens_puliti = [\n",
    "        clean_token(token.lemma_.lower())  # Lemmatizza, porta a minuscolo e pulisce il token\n",
    "        for token in doc\n",
    "        if not token.is_punct and not token.is_stop \n",
    "    ]\n",
    "    \n",
    "    # Ricombina i token in una stringa\n",
    "    return \" \".join(tokens_puliti)\n",
    "\n",
    "# Applica il preprocessing solo alle prime 100 righe della colonna 'testo_combinato'\n",
    "merged_dataset['testo_combinato_preprocessed'] = merged_dataset['testo_combinato'].apply(preprocess_text)\n",
    "\n",
    "# Visualizza i risultati per le prime 100 righe\n",
    "print(merged_dataset[['testo_combinato', 'testo_combinato_preprocessed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## PRE-PROCESSING vecchio ##########################\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Carica il modello SpaCy per l'italiano\n",
    "nlp = spacy.load(\"it_core_news_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Funzione per pulire i token\n",
    "def clean_token(token):\n",
    "\n",
    "    # Rimuovi numeri con virgola\n",
    "    if re.match(r'^\\d{1,3}(?:,\\d{1,3})$', token):\n",
    "        return ''  # Scarta il token\n",
    "\n",
    "    # Mantieni numeri, lettere, rimuovendo altri caratteri speciali\n",
    "    cleaned_token = re.sub(r'[^a-zA-Z0-9]', '', token) \n",
    "\n",
    "    # Scarta il token se è composto solo da un carattere o solo da un numero\n",
    "    if re.match(r'^\\d+$', cleaned_token):  # Se è solo un numero, scartalo\n",
    "        return ''\n",
    "    return '' if len(cleaned_token) == 1 else cleaned_token\n",
    "\n",
    "# Funzione per tokenizzare e preprocessare\n",
    "def preprocess_text(row):\n",
    "    if not isinstance(row, str):  # Verifica che row sia una stringa\n",
    "        return \"\"  # Restituisce una stringa vuota se non è valida (ovvero quando vede un nan restiruisce una stringa vuota)\n",
    "    \n",
    "    # Rimuove date nel formato 'dd/mm/yyyy' e 'dd/mm/yy'\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', '', row)\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}', '', row)  # Rimuove numeri separati da /\n",
    "\n",
    "    # Gestisci i punti tra le parole (ad esempio \"v.analisi\" diventa \"v analisi\")\n",
    "    row = re.sub(r'(\\w)\\.(\\w)', r'\\1 \\2', row)  # Aggiunge uno spazio tra parole separate da punto\n",
    "\n",
    "        \n",
    "    # Tokenizza il testo con SpaCy\n",
    "    doc = nlp(row)\n",
    "    \n",
    "    # Filtra stopwords e punteggiatura\n",
    "    tokens_puliti = [\n",
    "        clean_token(token.lemma_.lower())  # Lemmatizza, porta a minuscolo e pulisce il token\n",
    "        for token in doc\n",
    "        if not token.is_punct and not token.is_stop \n",
    "    ]\n",
    "    \n",
    "    # Ricombina i token in una stringa\n",
    "    return \" \".join(tokens_puliti)\n",
    "\n",
    "# Applica il preprocessing della colonna 'testo_combinato'\n",
    "merged_dataset['testo_combinato_preprocessed'] = merged_dataset['testo_combinato'].apply(preprocess_text)\n",
    "\n",
    "# Visualizza i risultati per le prime righe\n",
    "print(merged_dataset[['testo_combinato', 'testo_combinato_preprocessed']].head(10))\n",
    "\n",
    "# Visualizza i risultati \n",
    "print(merged_dataset[['testo_combinato', 'testo_combinato_preprocessed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### PRE PROCESSING NUOVO di word2vec ################\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Carica il modello SpaCy per l'italiano\n",
    "nlp = spacy.load(\"it_core_news_lg\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "def clean_token(token):\n",
    "\n",
    "    # Rimuovi caratteri non alfanumerici (inclusi simboli, punteggiatura, numeri, ecc.) e sostituiscili con uno spazio\n",
    "    cleaned_token = re.sub(r'[^a-zA-ZàèéìòùÀÈÉÌÒÙ]', ' ', token)\n",
    "    cleaned_token = re.sub(r'\\s+', ' ', cleaned_token).strip()  # Normalizza gli spazi multipli\n",
    "\n",
    "    return cleaned_token\n",
    "\n",
    "    \n",
    "# Funzione per tokenizzare e preprocessare il testo\n",
    "def preprocess_text(row):\n",
    "    if not isinstance(row, str):  # Verifica che il dato sia una stringa valida\n",
    "        return \"\"  # Restituisce una stringa vuota se non valido\n",
    "    \n",
    "    # Rimuove date nel formato 'dd/mm/yyyy' e 'dd/mm/yy'\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', '', row)\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}', '', row)  # Rimuove numeri separati da /\n",
    "      \n",
    "    # Aggiunge spazi tra numeri e lettere (es. \"800duloxetina\" -> \"800 duloxetina\")\n",
    "    row = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', row)\n",
    "    row = re.sub(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', row)\n",
    "\n",
    "    # Aggiunge spazi tra parole composte tipo \"vediAllegato\" -> \"vedi Allegato\"\n",
    "    row = re.sub(r'([a-zàèéìòù])([A-ZÀÈÉÌÒÙ])', r'\\1 \\2', row)\n",
    "\n",
    "    # normalizza  spazi (se ci sono più spazi consecutivi, vengono ridotti a uno solo) e rimuove  spazi all'inizio e alla fine della stringa\n",
    "    row = re.sub(r'[^\\w\\s]', ' ', row)  # Rimuove caratteri non alfanumerici e parentesi\n",
    "\n",
    "    doc = nlp(row)\n",
    "   \n",
    "    # Filtra e normalizza i token\n",
    "    tokens_puliti = [\n",
    "        clean_token(token.lemma_.lower())\n",
    "        for token in doc\n",
    "        if not token.is_punct and not token.is_stop and len(token.text) > 1 #and token.text.isalpha() \n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Applica un filtro finale per rimuovere manualmente le lettere singole\n",
    "    tokens_puliti = [token for token in tokens_puliti if len(token) > 1]  # Assicura che tutte le parole siano > 1 carattere\n",
    "    \n",
    "\n",
    "    # Ricombina i token in una stringa\n",
    "    return \" \".join(tokens_puliti)\n",
    "\n",
    "# Applica il preprocessing della colonna 'testo_combinato'\n",
    "merged_dataset['testo_combinato_preprocessed'] = merged_dataset['testo_combinato'].apply(preprocess_text)\n",
    "\n",
    "# Applica il preprocessing solo alle prime 100 righe\n",
    "#merged_dataset['testo_combinato_preprocessed'] = \"\"\n",
    "#merged_dataset.loc[:199, 'testo_combinato_preprocessed'] = merged_dataset.loc[:199, 'testo_combinato'].apply(preprocess_text)\n",
    "\n",
    "# Visualizza i risultati per le prime righe\n",
    "print(merged_dataset[['testo_combinato', 'testo_combinato_preprocessed']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### MEDIA NUMERO DI PAROLE TESTO PRE PROCESSATO ###########################\n",
    "\n",
    "# Funzione per calcolare il numero di parole\n",
    "def count_words(text):\n",
    "    if isinstance(text, str):  # Verifica se il testo è una stringa\n",
    "        return len(text.split())  # Conta le parole\n",
    "    elif isinstance(text, (int, float)):  # Se è un numero\n",
    "        return 1  # Considera il numero come una parola\n",
    "    return 0  # Restituisce 0 se non è una stringa o un numero\n",
    "\n",
    "# Calcola la lunghezza media in parole della colonna di testo combinato\n",
    "word_counts_combined = merged_dataset['testo_combinato_preprocessed'].apply(count_words)  # Conta le parole in ogni stringa\n",
    "average_word_count_combined = word_counts_combined.mean()  # Calcola la lunghezza media\n",
    "print(f\"Lunghezza media della colonna 'testo_combinato' preprocessato in parole: {average_word_count_combined:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ ISTOGRAMMA LUNGHEZZA TESTO CMBINATO PRE-PROCESSATO #############################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcola la lunghezza del testo combinato\n",
    "word_counts_combined = merged_dataset['testo_combinato_preprocessed'].apply(count_words)\n",
    "\n",
    "# Calcola i valori minimi e massimi\n",
    "lunghezza_min = word_counts_combined.min()\n",
    "lunghezza_max = word_counts_combined.max()\n",
    "\n",
    "# Definisce il numero di bin\n",
    "num_bin = 10\n",
    "\n",
    "# Calcola la larghezza delle bin\n",
    "bin_width = (lunghezza_max - lunghezza_min) / num_bin\n",
    "\n",
    "# Crea una lista di bin\n",
    "bins = [lunghezza_min + i * bin_width for i in range(num_bin + 1)]\n",
    "\n",
    "# Crea la figura più larga\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Calcola l'istogramma e i valori delle altezze (n) e dei bin\n",
    "n, bins, patches = plt.hist(\n",
    "    word_counts_combined,  # Usa i conteggi delle parole già calcolati\n",
    "    bins=bins,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Applica la scala logaritmica sull'asse y\n",
    "plt.yscale('log')\n",
    "\n",
    "# Calcola e aggiungi la linea della lunghezza media del testo combinato\n",
    "average_word_count_combined = word_counts_combined.mean()  # Questo ora è un valore scalare\n",
    "plt.axvline(x=average_word_count_combined, color='red', linestyle='--', label='Lunghezza media testo combinato preprocessato')\n",
    "\n",
    "# Aggiunge il titolo e le etichette degli assi\n",
    "plt.title('Distribuzione della lunghezza dei testi su 10 intervalli di parole')\n",
    "plt.xlabel('Intervalli di parole')\n",
    "plt.ylabel('Numero di testi')\n",
    "\n",
    "# Mostra le etichette delle bin\n",
    "plt.xticks(bins)\n",
    "\n",
    "# Aggiunge una label con il valore sopra ogni barra\n",
    "for i in range(len(n)):\n",
    "    plt.text(bins[i] + bin_width / 2, n[i], str(int(n[i])), ha='center', va='bottom')\n",
    "\n",
    "# Mostra la legenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n",
    "\n",
    "# Stampa i valori minimi e massimi del testo combinato\n",
    "print(f\"Lunghezza massima testo_combinato preprocessato (in parole): {lunghezza_max}\")\n",
    "print(f\"Lunghezza minima testo_combinato preprocessato (in parole): {lunghezza_min}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_dataset['testo_combinato'][2])\n",
    "print(merged_dataset['testo_combinato_preprocessed'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### DIMENSIONE VOCABOLARIO PRE-PROCESSATO ######################\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Calcola il vocabolario dalla colonna 'testo_combinato_preprocessed'\n",
    "vocab_set = set()\n",
    "for testo in merged_dataset['testo_combinato_preprocessed']:\n",
    "    if isinstance(testo, str):  # Assicurati che il testo non sia NaN\n",
    "        vocab_set.update(testo.split())\n",
    "\n",
    "# Calcola la dimensione del vocabolario\n",
    "vocabolario_dimensione = len(vocab_set)\n",
    "\n",
    "# Vettorizzazione usando TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Filtra i NaN e vettorizza le prime 200 righe di 'testo_combinato_preprocessed'\n",
    "valid_texts = merged_dataset['testo_combinato_preprocessed'].dropna() # Rimuove i NaN\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(valid_texts)\n",
    "\n",
    "# Numero di features (parole) nella matrice TF-IDF\n",
    "num_features = tfidf_matrix.shape[1]\n",
    "\n",
    "# Confronto tra dimensione del vocabolario e numero di features\n",
    "print(\"Dimensione del vocabolario:\", vocabolario_dimensione)\n",
    "print(\"Numero di features nella matrice TF-IDF:\", num_features)\n",
    "\n",
    "# Verifica dell'uguaglianza\n",
    "if vocabolario_dimensione == num_features:\n",
    "    print(\"La dimensione del vocabolario coincide con il numero di features nella matrice TF-IDF.\")\n",
    "else:\n",
    "    print(\"La dimensione del vocabolario NON coincide con il numero di features nella matrice TF-IDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni il vocabolario dal TfidfVectorizer\n",
    "vectorizer_vocab = set(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Parole nel tuo vocabolario che non sono nel vocabolario del TfidfVectorizer\n",
    "missing_in_tfidf = vocab_set - vectorizer_vocab\n",
    "\n",
    "# Parole nel vocabolario del TfidfVectorizer che non sono nel tuo vocabolario\n",
    "extra_in_tfidf = vectorizer_vocab - vocab_set\n",
    "\n",
    "# Stampa le parole mancanti e extra\n",
    "print(\"Parole presenti nel vocabolario manuale ma non nel vocabolario del TF-IDF:\")\n",
    "print(missing_in_tfidf)\n",
    "\n",
    "print(\"\\nParole presenti nel vocabolario del TF-IDF ma non nel vocabolario manuale:\")\n",
    "print(extra_in_tfidf)\n",
    "\n",
    "# Puoi anche stampare il numero di parole mancanti ed extra\n",
    "print(\"\\nNumero di parole mancanti:\", len(missing_in_tfidf))\n",
    "print(\"Numero di parole extra:\", len(extra_in_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## CLASSIFIERS #################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Definisci una lista di classificatori che vuoi provare\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(n_jobs=-1, max_depth=10, max_features=0.1, random_state=42),\n",
    "    #'RandomForest': RandomForestClassifier(n_jobs=-1, max_depth=10, random_state=42),\n",
    "    #'LogisticRegression': LogisticRegression(random_state=42, max_iter=200),\n",
    "    #'SVM': SVC(probability=True,random_state=42),\n",
    "    #'KNeighbors': KNeighborsClassifier(),\n",
    "    #'DecisionTree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    #'DecisionTree': DecisionTreeClassifier(max_depth=20, random_state=42),\n",
    "    #'GradientBoosting': GradientBoostingClassifier(learning_rate=0.01, max_depth=6, random_state=42),\n",
    "    #'extremeGradientBoosting': XGBClassifier( learning_rate=0.1, random_state=42, n_jobs=-1, max_depth=6),\n",
    "    #'mlp': MLPClassifier(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=200, alpha=0.0001, learning_rate_init=0.01, batch_size=256, early_stopping=True),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### weighted TFIDF VECTORIZER ############################\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class Wcbtfidf(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_features, custom_weights=None):  \n",
    "        self.max_features = max_features\n",
    "        self.custom_weights = custom_weights  \n",
    "        self.combine_vocab = []\n",
    "        self.class_wise_vocab = {}\n",
    "        self.final_tfidf = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(y, pd.Series):\n",
    "            y = pd.Series(y)\n",
    "\n",
    "        if not isinstance(X, pd.Series):\n",
    "            X = pd.Series(X)\n",
    "\n",
    "        if self.custom_weights is None:\n",
    "            self.custom_weights = y.value_counts(normalize=True).to_dict()\n",
    "            total = 0\n",
    "            weights = {}\n",
    "            \n",
    "            for key, val in self.custom_weights.items():\n",
    "                weight = int(np.floor(val * self.max_features))  \n",
    "                weights[key] = weight\n",
    "                total += weight\n",
    "\n",
    "            # Distribuisci il resto per bilanciare la somma\n",
    "            remaining = self.max_features - total\n",
    "            sorted_labels = sorted(weights.keys(), key=lambda k: y.value_counts()[k], reverse=True)\n",
    "            for label in sorted_labels[:remaining]:\n",
    "                weights[label] += 1\n",
    "\n",
    "            self.custom_weights = weights\n",
    "\n",
    "        elif len(self.custom_weights.keys()) != y.nunique():\n",
    "            raise ValueError(\n",
    "                f\"Custom weights keys ({list(self.custom_weights.keys())}) do not match the number of unique labels in y ({y.unique()}).\"\n",
    "            )\n",
    "        elif np.sum(list(self.custom_weights.values())) != self.max_features:\n",
    "            raise ValueError(\n",
    "                f\"The sum of custom weights ({np.sum(list(self.custom_weights.values()))}) does not match max_features ({self.max_features}).\"\n",
    "            )\n",
    "\n",
    "        # Debugging output \n",
    "        print(f\"Calcolo automatico pesi: {self.custom_weights}\")\n",
    "        print(f\"Somma pesi: {np.sum(list(self.custom_weights.values()))}, max_features: {self.max_features}\")\n",
    "        \n",
    "        self.combine_vocab = self.return_total_vocab(X, y, self.custom_weights)\n",
    "        self.final_tfidf = TfidfVectorizer(vocabulary=self.combine_vocab)  # Nessuna lista di stopwords\n",
    "        self.final_tfidf.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.final_tfidf is None:\n",
    "            raise ValueError(\"The fit method must be called before transform.\")\n",
    "        transformed_data = self.final_tfidf.transform(X)\n",
    "        return pd.DataFrame(transformed_data.toarray(), columns=self.final_tfidf.get_feature_names_out())\n",
    "\n",
    "    #def return_total_vocab(self, X, y, label_dict):\n",
    "        total_vocab = []\n",
    "        exclude = []  # Initialize an empty list to track excluded words (non-overlapping)\n",
    "    \n",
    "        for key, val in label_dict.items():\n",
    "            if val != 0:\n",
    "                slice_data = X[y == key]\n",
    "                tfidf = TfidfVectorizer(max_features=val, stop_words=exclude)\n",
    "                tfidf.fit(slice_data)\n",
    "                vocab = list(tfidf.get_feature_names_out())\n",
    "                total_vocab.extend(vocab)\n",
    "                exclude.extend(vocab)  # Update the exclude list with features from this class\n",
    "                self.class_wise_vocab[key] = vocab\n",
    "            else:\n",
    "                self.class_wise_vocab[key] = []\n",
    "    \n",
    "        return total_vocab\n",
    "    \n",
    "\n",
    "    def return_total_vocab(self, X, y, label_dict):\n",
    "        total_vocab = {}  # Dizionario per il vocabolario finale (parola -> valore TF-IDF)\n",
    "\n",
    "        # Itera sulle classi e calcola il TF-IDF per ciascuna\n",
    "        for key, val in label_dict.items():\n",
    "            if val != 0:\n",
    "                slice_data = X[y == key]  # Dati della classe corrente\n",
    "                tfidf = TfidfVectorizer(max_features=val)  # Calcola il TF-IDF senza esclusioni\n",
    "                tfidf.fit(slice_data)  # Calcola il TF-IDF per questa classe\n",
    "                \n",
    "                # Ottieni le parole e i rispettivi valori TF-IDF\n",
    "                tfidf_matrix = tfidf.transform(slice_data)  # Calcola i valori TF-IDF per slice_data\n",
    "                feature_names = tfidf.get_feature_names_out()  # Ottieni le parole\n",
    "                tfidf_values = np.array(tfidf_matrix.sum(axis=0)).flatten()  # Somma i valori TF-IDF per ciascuna parola\n",
    "                \n",
    "                # Per ogni parola, aggiorna il dizionario con la somma dei valori TF-IDF\n",
    "                for word, tfidf_value in zip(feature_names, tfidf_values):\n",
    "                    if word in total_vocab:\n",
    "                        #total_vocab[word] = max(total_vocab[word], tfidf_value)  # Prendi il massimo\n",
    "                        total_vocab[word] = (total_vocab[word] + tfidf_value) / 2  # Calcola la media\n",
    "                    else:\n",
    "                        total_vocab[word] = tfidf_value  # Aggiungi la parola con il suo valore TF-IDF\n",
    "\n",
    "                self.class_wise_vocab[key] = list(feature_names)  # Salva il vocabolario per la classe\n",
    "\n",
    "        # Ordina il vocabolario finale in base al valore di TF-IDF (dal più alto al più basso)\n",
    "        sorted_vocab = sorted(total_vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "        # Prendi solo i primi 'max_features' vocabolari\n",
    "        final_vocab = [word for word, value in sorted_vocab[:self.max_features]]\n",
    "        \n",
    "        return final_vocab  # Restituisce il vocabolario finale con parole uniche e i loro valori aggregati\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### CROSS VALIDATION #########################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Funzione modificata per includere la media delle features\n",
    "def eval_cross_validation(pipeline, X, y, skf):\n",
    "    list_reports = []\n",
    "    list_f1 = []\n",
    "    list_auc = []  # Lista per raccogliere i valori di AUC mediati\n",
    "    list_num_features = []  # Lista per raccogliere il numero di features per ogni fold\n",
    "    \n",
    "    # Crea una lista per raccogliere precision, recall e f1-score mediati\n",
    "    precision_sum = {}\n",
    "    recall_sum = {}\n",
    "    f1_sum = {}\n",
    "    \n",
    "    # Liste per la deviazione standard\n",
    "    precision_values = {}\n",
    "    recall_values = {}\n",
    "    f1_values = {}\n",
    "\n",
    "    # Inizializza il supporto per ogni classe\n",
    "    unique_labels = y.unique()\n",
    "    support_sum = {str(label): 0 for label in unique_labels}  # Assicurati che le etichette siano stringhe\n",
    "\n",
    "    for train, val in skf.split(X, y):\n",
    "        X_tr = X.values[train]\n",
    "        y_tr = y.values[train]\n",
    "        X_val = X.values[val]\n",
    "        y_val = y.values[val]\n",
    "\n",
    "        # Addestra il pipeline sul training set\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "        # Previsioni sul validation set\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        y_pred_prob = pipeline.predict_proba(X_val)[:, 1]  # Probabilità della classe positiva\n",
    "\n",
    "        # Crea il classification report come dizionario\n",
    "        cr = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "        # Aggiungi il report alla lista\n",
    "        list_reports.append(cr)\n",
    "\n",
    "        # Estrai il F1-score\n",
    "        list_f1.append(cr['weighted avg']['f1-score'])\n",
    "\n",
    "        # Calcola l'AUC per questo fold\n",
    "        auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "        list_auc.append(auc_score)\n",
    "\n",
    "        # Raccogli il numero di features per questo fold\n",
    "        X_tfidf = pipeline.named_steps['wcbtfidf'].transform(X_val)\n",
    "        list_num_features.append(X_tfidf.shape[1])  # Numero di features per questo fold\n",
    "\n",
    "        # Somma le metriche per ogni classe\n",
    "        for label, metrics in cr.items():\n",
    "            if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                precision_sum[label] = precision_sum.get(label, 0) + metrics['precision']\n",
    "                recall_sum[label] = recall_sum.get(label, 0) + metrics['recall']\n",
    "                f1_sum[label] = f1_sum.get(label, 0) + metrics['f1-score']\n",
    "\n",
    "                # Aggiungi valori per la deviazione standard\n",
    "                precision_values[label] = precision_values.get(label, []) + [metrics['precision']]\n",
    "                recall_values[label] = recall_values.get(label, []) + [metrics['recall']]\n",
    "                f1_values[label] = f1_values.get(label, []) + [metrics['f1-score']]\n",
    "\n",
    "                # Somma il supporto per questa fold\n",
    "                support_sum[str(label)] += metrics['support']  # Usa str(label) per garantire la corrispondenza\n",
    "\n",
    "    # Calcola la media dell'AUC\n",
    "    auc_avg = np.mean(list_auc)\n",
    "\n",
    "    # Calcola la media del numero di features\n",
    "    num_features_avg = np.mean(list_num_features)\n",
    "\n",
    "    # Calcola la media delle metriche per ogni classe\n",
    "    num_folds = skf.get_n_splits()\n",
    "    precision_avg = {label: precision_sum[label] / num_folds for label in precision_sum}\n",
    "    recall_avg = {label: recall_sum[label] / num_folds for label in recall_sum}\n",
    "    f1_avg_per_class = {label: f1_sum[label] / num_folds for label in f1_sum}\n",
    "\n",
    "    # Calcola la deviazione standard per ogni metrica\n",
    "    precision_std = {label: np.std(precision_values[label]) for label in precision_values}\n",
    "    recall_std = {label: np.std(recall_values[label]) for label in recall_values}\n",
    "    f1_std = {label: np.std(f1_values[label]) for label in f1_values}\n",
    "\n",
    "    # Calcola il supporto medio per ciascuna classe\n",
    "    support_avg = {label: support_sum[label] / num_folds for label in support_sum}\n",
    "\n",
    "    # Crea un DataFrame per visualizzare le metriche\n",
    "    df_avg = pd.DataFrame({\n",
    "        'Precision': precision_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'F1-Score': f1_avg_per_class,\n",
    "        'Precision Std': precision_std,\n",
    "        'Recall Std': recall_std,\n",
    "        'F1-Score Std': f1_std,\n",
    "        'Support': support_avg,  # Supporto medio\n",
    "        'Avg Features': num_features_avg,  # Media delle features\n",
    "    })  # Trasponi per avere le classi come righe\n",
    "\n",
    "    return df_avg, auc_avg, f1_avg_per_class, num_features_avg \n",
    "\n",
    "# Crea un oggetto StratifiedKFold per la cross-validation stratificata\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from imblearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "X = merged_dataset['testo_combinato_preprocessed'].fillna(\"\")  # Riempie eventuali NaN con stringhe vuote\n",
    "y = merged_dataset['positivi']\n",
    "\n",
    "# Loop per ogni classificatore\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "    \n",
    "    # Configura il pipeline con Wcbtfidf e il classificatore\n",
    "    pipeline = Pipeline([\n",
    "        ('wcbtfidf', Wcbtfidf(max_features=5000)),  # Imposta max_features; verifica se è sufficiente per il dataset\n",
    "        #('smote', SMOTE(random_state=42)),\n",
    "        ('smote', SMOTE(random_state=42, sampling_strategy= 0.1 )),  # Applica SMOTE prima per la classe minoritaria\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy= 'auto', random_state=42)),  # Poi undersampling della classe maggioritaria\n",
    "        ('classificazione', clf)\n",
    "    ])\n",
    "\n",
    "    # Esegui la cross-validation\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "    \n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### APPROCCI DEL PAPER SU TFIDF ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### TFIDF ICF VECTORIZER ############################\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class TfidfIcfVectorizer(TfidfVectorizer):\n",
    "    def fit_transform(self, X, y):\n",
    "        tfidf_matrix = super().fit_transform(X)\n",
    "        self.icf_weights = self._compute_icf_weights(tfidf_matrix, y)\n",
    "        return tfidf_matrix.multiply(self.icf_weights)\n",
    "\n",
    "    def _compute_icf_weights(self, tfidf_matrix, y):\n",
    "        # Numero totale di documenti\n",
    "        N = tfidf_matrix.shape[0]\n",
    "\n",
    "        # Matrice booleana: 1 se un termine è presente nel documento\n",
    "        term_presence = (tfidf_matrix > 0).astype(int)\n",
    "\n",
    "        # Calcolo del numero di documenti per classe\n",
    "        classes, class_counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        # Array per memorizzare i pesi ICF\n",
    "        icf_weights = np.zeros((tfidf_matrix.shape[1], len(classes)))\n",
    "\n",
    "        for idx, class_label in enumerate(classes):\n",
    "            class_mask = (y == class_label)\n",
    "            term_docs_in_class = term_presence[class_mask].sum(axis=0)\n",
    "\n",
    "            # Calcolo ICF con smoothing, bilanciando l'effetto delle classi\n",
    "            icf_weights[:, idx] = np.log((N + 1) / (1 + term_docs_in_class)).A1\n",
    "\n",
    "        # Media ponderata dei pesi ICF su tutte le classi, usando la dimensione della classe come peso\n",
    "        class_weights = class_counts / N\n",
    "        weighted_icf = np.average(icf_weights, axis=1, weights=class_weights)\n",
    "        \n",
    "        return weighted_icf.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### TFIDF RF VECTORIZER ############################\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "class TfidfRfVectorizer(TfidfVectorizer):\n",
    "    def fit_transform(self, X, y):\n",
    "        tf_matrix = super().fit_transform(X)  # Calcola la matrice TF\n",
    "        rf_weights = self._compute_rf_weights(tf_matrix, y)  # Calcola i pesi RF\n",
    "        return tf_matrix.multiply(rf_weights)\n",
    "\n",
    "    def _compute_rf_weights(self, tf_matrix, y):\n",
    "        # Numero totale di documenti\n",
    "        N = tf_matrix.shape[0]\n",
    "\n",
    "        # Trova il numero di documenti in cui un termine è presente per ciascuna classe\n",
    "        term_presence = (tf_matrix > 0).astype(int)  # matrice booleana\n",
    "        classes, class_counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        # Inizializza i pesi RF a 1 (per evitare di avere zero all'inizio)\n",
    "        rf_weights = np.ones(tf_matrix.shape[1])\n",
    "\n",
    "        # Calcola i pesi di rilevanza per ogni termine in ogni classe\n",
    "        for class_idx, class_label in enumerate(classes):\n",
    "            class_mask = (y == class_label)\n",
    "            term_docs_in_class = term_presence[class_mask].sum(axis=0)  # Conta i termini nella classe\n",
    "            term_docs_in_class = np.asarray(term_docs_in_class).flatten()  # Converte in un array piatto\n",
    "\n",
    "            # Calcola la frequenza di rilevanza per ciascun termine\n",
    "            rf_weights += term_docs_in_class / class_counts[class_idx]  # Frequenza di rilevanza\n",
    "\n",
    "        # Assicurati che i pesi siano una matrice con la forma corretta\n",
    "        return rf_weights.reshape(1, -1)  # Riformatta come una matrice 1 x numero di termini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### TFIDF IGM VECTORIZER ############################\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class TfidfIgmVectorizer(TfidfVectorizer):\n",
    "    def __init__(self, lambda_coefficient=7.0, max_features=None):\n",
    "        super().__init__(max_features=max_features)  # Passa il parametro max_features al TfidfVectorizer\n",
    "        self.lambda_coefficient = lambda_coefficient\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        # Calcola la matrice TF\n",
    "        tf_matrix = super().fit_transform(X)  # Calcola la matrice TF-IDF\n",
    "        igm_weights = self._compute_igm_weights(tf_matrix, y)  # Calcola i pesi IGM\n",
    "        #sqrt_tf_matrix = np.sqrt(tf_matrix.toarray())  # Applica la radice quadrata alla matrice TF\n",
    "        #return sqrt_tf_matrix * (1 + self.lambda_coefficient + igm_weights)  # Applica la formula\n",
    "        return tf_matrix.multiply(igm_weights)  # Applica i pesi IGM alla matrice TF\n",
    "    \n",
    "    \n",
    "    def _compute_igm_weights(self, tf_matrix, y):\n",
    "        # Numero totale di documenti\n",
    "        N = tf_matrix.shape[0]\n",
    "        num_features = tf_matrix.shape[1]\n",
    "\n",
    "        # Trova la frequenza del termine nelle diverse classi\n",
    "        term_presence = (tf_matrix > 0).astype(int)  # matrice booleana: presenza del termine nei documenti\n",
    "        classes = np.unique(y)  # Classi uniche e il loro numero\n",
    "\n",
    "        # Inizializza i pesi IGM a 1 (per evitare divisioni per zero)\n",
    "        igm_weights = np.ones(num_features)\n",
    "\n",
    "        # Calcola la frequenza dei termini per ogni classe\n",
    "        term_docs_in_class = np.zeros((len(classes), num_features))  # matrice di frequenza per classe e termine\n",
    "\n",
    "        # Per ogni classe, calcoliamo quante volte ogni termine appare nei documenti della classe\n",
    "        for class_idx, class_label in enumerate(classes):\n",
    "            class_mask = (y == class_label)  # Maschera per la classe corrente\n",
    "            term_docs_in_class[class_idx] = term_presence[class_mask].sum(axis=0)  # Somma le occorrenze di termini nella classe\n",
    "\n",
    "        # Calcola i pesi IGM per ogni termine\n",
    "        total_term_docs = term_docs_in_class.sum(axis=0)  # Somma delle frequenze dei termini (per tutte le classi)\n",
    "\n",
    "        # Calcola i pesi IGM usando il termine di rilevanza (senza cicli annidati)\n",
    "        for class_idx in range(len(classes)):\n",
    "            class_term_docs = term_docs_in_class[class_idx]\n",
    "            relevant_term_docs = class_term_docs / total_term_docs  # Rilevanza di ciascun termine\n",
    "\n",
    "            # Aggiorna i pesi IGM\n",
    "            igm_weights += self.lambda_coefficient + relevant_term_docs\n",
    "\n",
    "        # Ritorna i pesi IGM come matrice di forma (1, num_features)\n",
    "        return igm_weights.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### CROSS VALIDATION CON TF-IDF-ICF #########################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# Funzione modificata per includere la media delle features\n",
    "def eval_cross_validation(pipeline, X, y, skf):\n",
    "    list_reports = []\n",
    "    list_f1 = []\n",
    "    list_auc = []  # Lista per raccogliere i valori di AUC mediati\n",
    "    list_num_features = []  # Lista per raccogliere il numero di features per ogni fold\n",
    "    \n",
    "    # Crea una lista per raccogliere precision, recall e f1-score mediati\n",
    "    precision_sum = {}\n",
    "    recall_sum = {}\n",
    "    f1_sum = {}\n",
    "    \n",
    "    # Liste per la deviazione standard\n",
    "    precision_values = {}\n",
    "    recall_values = {}\n",
    "    f1_values = {}\n",
    "\n",
    "    # Inizializza il supporto per ogni classe\n",
    "    unique_labels = y.unique()\n",
    "    support_sum = {str(label): 0 for label in unique_labels}  # Assicurati che le etichette siano stringhe\n",
    "\n",
    "    for train, val in skf.split(X, y):\n",
    "        X_tr = X.iloc[train]  # differenza con 'baseline1'\n",
    "        y_tr = y.iloc[train]\n",
    "        X_val = X.iloc[val]\n",
    "        y_val = y.iloc[val]\n",
    "\n",
    "        # Addestra il pipeline sul training set\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "        # Previsioni sul validation set\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        y_pred_prob = pipeline.predict_proba(X_val)[:, 1]  # Probabilità della classe positiva\n",
    "\n",
    "        # Crea il classification report come dizionario\n",
    "        cr = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "        # Aggiungi il report alla lista\n",
    "        list_reports.append(cr)\n",
    "\n",
    "        # Estrai il F1-score\n",
    "        list_f1.append(cr['weighted avg']['f1-score'])\n",
    "\n",
    "        # Calcola l'AUC per questo fold\n",
    "        auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "        list_auc.append(auc_score)\n",
    "\n",
    "        # Raccogli il numero di features per questo fold\n",
    "        X_tfidf = pipeline.named_steps['tfidf_igm'].transform(X_val)  # Modificato per estrarre la trasformazione\n",
    "        list_num_features.append(X_tfidf.shape[1])  # Numero di features per questo fold\n",
    "\n",
    "        # Somma le metriche per ogni classe\n",
    "        for label, metrics in cr.items():\n",
    "            if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                precision_sum[label] = precision_sum.get(label, 0) + metrics['precision']\n",
    "                recall_sum[label] = recall_sum.get(label, 0) + metrics['recall']\n",
    "                f1_sum[label] = f1_sum.get(label, 0) + metrics['f1-score']\n",
    "\n",
    "                # Aggiungi valori per la deviazione standard\n",
    "                precision_values[label] = precision_values.get(label, []) + [metrics['precision']]\n",
    "                recall_values[label] = recall_values.get(label, []) + [metrics['recall']]\n",
    "                f1_values[label] = f1_values.get(label, []) + [metrics['f1-score']]\n",
    "\n",
    "                # Somma il supporto per questa fold\n",
    "                support_sum[str(label)] += metrics['support']  # Usa str(label) per garantire la corrispondenza\n",
    "\n",
    "    # Calcola la media dell'AUC\n",
    "    auc_avg = np.mean(list_auc)\n",
    "\n",
    "    # Calcola la media del numero di features\n",
    "    num_features_avg = np.mean(list_num_features)\n",
    "\n",
    "    # Calcola la media delle metriche per ogni classe\n",
    "    num_folds = skf.get_n_splits()\n",
    "    precision_avg = {label: precision_sum[label] / num_folds for label in precision_sum}\n",
    "    recall_avg = {label: recall_sum[label] / num_folds for label in recall_sum}\n",
    "    f1_avg_per_class = {label: f1_sum[label] / num_folds for label in f1_sum}\n",
    "\n",
    "    # Calcola la deviazione standard per ogni metrica\n",
    "    precision_std = {label: np.std(precision_values[label]) for label in precision_values}\n",
    "    recall_std = {label: np.std(recall_values[label]) for label in recall_values}\n",
    "    f1_std = {label: np.std(f1_values[label]) for label in f1_values}\n",
    "\n",
    "    # Calcola il supporto medio per ciascuna classe\n",
    "    support_avg = {label: support_sum[label] / num_folds for label in support_sum}\n",
    "\n",
    "    # Crea un DataFrame per visualizzare le metriche\n",
    "    df_avg = pd.DataFrame({\n",
    "        'Precision': precision_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'F1-Score': f1_avg_per_class,\n",
    "        'Precision Std': precision_std,\n",
    "        'Recall Std': recall_std,\n",
    "        'F1-Score Std': f1_std,\n",
    "        'Support': support_avg,  # Supporto medio\n",
    "        'Avg Features': num_features_avg,  # Media delle features\n",
    "    })  # Trasponi per avere le classi come righe\n",
    "\n",
    "    return df_avg, auc_avg, f1_avg_per_class, num_features_avg \n",
    " \n",
    "\n",
    "# Crea un oggetto StratifiedKFold per la cross-validation stratificata\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from imblearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "X = merged_dataset['testo_combinato_preprocessed'].fillna(\"\")  # Riempie eventuali NaN con stringhe vuote\n",
    "y = merged_dataset['positivi']\n",
    "\n",
    "# Loop per ogni classificatore\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "    \n",
    "    # Configura il pipeline con Wcbtfidf e il classificatore\n",
    "    pipeline = Pipeline([\n",
    "        #('tfidf_icf', TfidfIcfVectorizer(max_features=5000)),  # Imposta max_features; verifica se è sufficiente per il dataset\n",
    "        #('tfidf_rf', TfidfRfVectorizer(max_features=5000)),\n",
    "        ('tfidf_igm', TfidfIgmVectorizer(max_features=5000)),\n",
    "        #('smote', SMOTE(random_state=42)),\n",
    "        ('smote', SMOTE(random_state=42, sampling_strategy= 0.1 )),  # Applica SMOTE prima per la classe minoritaria\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy= 'auto', random_state=42)),  # Poi undersampling della classe maggioritaria\n",
    "        ('classificazione', clf)\n",
    "    ])\n",
    "\n",
    "    # Esegui la cross-validation\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "    \n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### CROSS VALIDATION #########################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Funzione modificata per includere la media delle features\n",
    "def eval_cross_validation(pipeline, X, y, skf):\n",
    "    list_reports = []\n",
    "    list_f1 = []\n",
    "    list_auc = []  # Lista per raccogliere i valori di AUC mediati\n",
    "    list_num_features = []  # Lista per raccogliere il numero di features per ogni fold\n",
    "    \n",
    "    # Crea una lista per raccogliere precision, recall e f1-score mediati\n",
    "    precision_sum = {}\n",
    "    recall_sum = {}\n",
    "    f1_sum = {}\n",
    "    \n",
    "    # Liste per la deviazione standard\n",
    "    precision_values = {}\n",
    "    recall_values = {}\n",
    "    f1_values = {}\n",
    "\n",
    "    # Inizializza il supporto per ogni classe\n",
    "    unique_labels = y.unique()\n",
    "    support_sum = {str(label): 0 for label in unique_labels}  # Assicurati che le etichette siano stringhe\n",
    "\n",
    "    for train, val in skf.split(X, y):\n",
    "        X_tr = X.values[train]\n",
    "        y_tr = y.values[train]\n",
    "        X_val = X.values[val]\n",
    "        y_val = y.values[val]\n",
    "\n",
    "        # Addestra il pipeline sul training set\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "        # Previsioni sul validation set\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        y_pred_prob = pipeline.predict_proba(X_val)[:, 1]  # Probabilità della classe positiva\n",
    "\n",
    "        # Crea il classification report come dizionario\n",
    "        cr = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "        # Aggiungi il report alla lista\n",
    "        list_reports.append(cr)\n",
    "\n",
    "        # Estrai il F1-score\n",
    "        list_f1.append(cr['weighted avg']['f1-score'])\n",
    "\n",
    "        # Calcola l'AUC per questo fold\n",
    "        auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "        list_auc.append(auc_score)\n",
    "\n",
    "        # Raccogli il numero di features per questo fold\n",
    "        X_tfidf = pipeline.named_steps['tfidf'].transform(X_val)\n",
    "        list_num_features.append(X_tfidf.shape[1])  # Numero di features per questo fold\n",
    "\n",
    "        # Somma le metriche per ogni classe\n",
    "        for label, metrics in cr.items():\n",
    "            if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                precision_sum[label] = precision_sum.get(label, 0) + metrics['precision']\n",
    "                recall_sum[label] = recall_sum.get(label, 0) + metrics['recall']\n",
    "                f1_sum[label] = f1_sum.get(label, 0) + metrics['f1-score']\n",
    "\n",
    "                # Aggiungi valori per la deviazione standard\n",
    "                precision_values[label] = precision_values.get(label, []) + [metrics['precision']]\n",
    "                recall_values[label] = recall_values.get(label, []) + [metrics['recall']]\n",
    "                f1_values[label] = f1_values.get(label, []) + [metrics['f1-score']]\n",
    "\n",
    "                # Somma il supporto per questa fold\n",
    "                support_sum[str(label)] += metrics['support']  # Usa str(label) per garantire la corrispondenza\n",
    "\n",
    "    # Calcola la media dell'AUC\n",
    "    auc_avg = np.mean(list_auc)\n",
    "\n",
    "    # Calcola la media del numero di features\n",
    "    num_features_avg = np.mean(list_num_features)\n",
    "\n",
    "    # Calcola la media delle metriche per ogni classe\n",
    "    num_folds = skf.get_n_splits()\n",
    "    precision_avg = {label: precision_sum[label] / num_folds for label in precision_sum}\n",
    "    recall_avg = {label: recall_sum[label] / num_folds for label in recall_sum}\n",
    "    f1_avg_per_class = {label: f1_sum[label] / num_folds for label in f1_sum}\n",
    "\n",
    "    # Calcola la deviazione standard per ogni metrica\n",
    "    precision_std = {label: np.std(precision_values[label]) for label in precision_values}\n",
    "    recall_std = {label: np.std(recall_values[label]) for label in recall_values}\n",
    "    f1_std = {label: np.std(f1_values[label]) for label in f1_values}\n",
    "\n",
    "    # Calcola il supporto medio per ciascuna classe\n",
    "    support_avg = {label: support_sum[label] / num_folds for label in support_sum}\n",
    "\n",
    "    # Crea un DataFrame per visualizzare le metriche\n",
    "    df_avg = pd.DataFrame({\n",
    "        'Precision': precision_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'F1-Score': f1_avg_per_class,\n",
    "        'Precision Std': precision_std,\n",
    "        'Recall Std': recall_std,\n",
    "        'F1-Score Std': f1_std,\n",
    "        'Support': support_avg,  # Supporto medio\n",
    "        'Avg Features': num_features_avg,  # Media delle features\n",
    "    })  # Trasponi per avere le classi come righe\n",
    "\n",
    "    return df_avg, auc_avg, f1_avg_per_class, num_features_avg \n",
    "\n",
    "# Crea un oggetto StratifiedKFold per la cross-validation stratificata\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### CLASSIFICATION SENZA MAX FEATURES E SENZA SMOTE ############################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "#X = merged_dataset['testo_combinato_preprocessed'].fillna(\"\").astype(str)\n",
    "X = merged_dataset['testo_combinato_preprocessed']\n",
    "y = merged_dataset['positivi']\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "    \n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),  #VETTORIZZAZIONE SENZA MAX FEATURES\n",
    "        ('classificazione', clf)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline to the data\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Trasforma i dati e ottieni la matrice TF-IDF\n",
    "    X_tfidf = pipeline.named_steps['tfidf'].transform(X)\n",
    "\n",
    "    # Ottieni la dimensione della matrice TF-IDF\n",
    "    num_samples, num_features = X_tfidf.shape\n",
    "    print(f\"Dimensione della matrice TF-IDF: {num_samples} campioni, {num_features} features\")\n",
    "\n",
    "    # Calcola le metriche usando la funzione\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "    \n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    \n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### per stampare le probabilità delle classi ###################\n",
    "\n",
    "# Calcola le probabilità delle classi\n",
    "y_proba = cross_val_predict(pipeline, X, y, cv=skf, method='predict_proba')\n",
    "\n",
    "# Predici le classi con soglia 0.5\n",
    "y_pred = (y_proba[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "# Identifica gli esempi in cui il modello sbaglia\n",
    "error_indices = np.where(y_pred != y)[0]\n",
    "\n",
    "# Analizza le probabilità per i campioni sbagliati\n",
    "print(f\"Numero di errori: {len(error_indices)}\")\n",
    "print(\"Probabilità degli errori:\")\n",
    "for idx in error_indices[:10]:  # Mostra solo i primi 10 errori per brevità\n",
    "    print(f\"Esempio {idx}: Classe reale: {y[idx]}, Predetta: {y_pred[idx]}, \"\n",
    "          f\"Probabilità Classe 0: {y_proba[idx, 0]:.4f}, Classe 1: {y_proba[idx, 1]:.4f}\")\n",
    "\n",
    "# Calcola la differenza assoluta tra le probabilità delle due classi per gli errori\n",
    "proba_diff = np.abs(y_proba[error_indices, 0] - y_proba[error_indices, 1])\n",
    "\n",
    "# Mostra un'analisi delle differenze di probabilità per gli errori\n",
    "print(\"\\nAnalisi differenze probabilità degli errori:\")\n",
    "print(f\"Media differenza probabilità: {proba_diff.mean():.4f}\")\n",
    "print(f\"Minima differenza probabilità: {proba_diff.min():.4f}\")\n",
    "print(f\"Massima differenza probabilità: {proba_diff.max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### VALUTAZIONE SUL TRAINING CHE MOSTRA UNA SITUAZIONE DI OVERFITTING NEL RF ############################\n",
    "# ho provato senza max features e con e senza smote (senza max depth): il risultato è praticamente lo stesso\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "X = merged_dataset['testo_combinato_preprocessed']\n",
    "y = merged_dataset['positivi']\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "    \n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),  # Vettorizzazione senza max features\n",
    "        ('smote', SMOTE(random_state=42)), \n",
    "        ('classificazione', clf)\n",
    "    ])\n",
    "\n",
    "    # Inizializza StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    training_scores = []\n",
    "    validation_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "        # Dividi i dati\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Addestra il modello sul training set\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Previsioni sul training set\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "\n",
    "        # Previsioni sul test set\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Calcola le metriche sul training set\n",
    "        train_report = classification_report(y_train, y_train_pred, output_dict=True, zero_division=1)\n",
    "        training_scores.append(train_report['macro avg']['f1-score'])\n",
    "\n",
    "        # Calcola le metriche sul test set\n",
    "        test_report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=1)\n",
    "        validation_scores.append(test_report['macro avg']['f1-score'])\n",
    "\n",
    "        # Stampa le performance per il fold corrente\n",
    "        print(f\"\\nFold {fold} - Training Metrics\")\n",
    "        print(classification_report(y_train, y_train_pred, zero_division=1))\n",
    "        print(f\"Fold {fold} - Test Metrics\")\n",
    "        print(classification_report(y_test, y_test_pred, zero_division=1))\n",
    "\n",
    "        # Matrice di confusione per il fold corrente (opzionale)\n",
    "        ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "        plt.title(f\"Matrice di Confusione - {clf_name} - Fold {fold}\")\n",
    "        plt.show()\n",
    "\n",
    "    # Calcola e stampa le performance medie\n",
    "    print(f\"\\n### Risultati Medi - {clf_name} ###\")\n",
    "    print(f\"F1 Macro Medio (Training): {np.mean(training_scores):.4f}\")\n",
    "    print(f\"F1 Macro Medio (Validation): {np.mean(validation_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### grid search per max_features ############################\n",
    "################### con f1 ottengo None ma con auc ottengo 0.1 #######################à\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = merged_dataset['testo_combinato_preprocessed']\n",
    "y = merged_dataset['positivi']\n",
    "# Trasforma i dati con TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Definisci il classificatore Random Forest\n",
    "rf = RandomForestClassifier(random_state=42,n_jobs=-1)\n",
    "\n",
    "# Griglia dei valori di max_features\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 'log2', 0.1, 0.2, 0.5, None]\n",
    "}\n",
    "\n",
    "# Esegui GridSearchCV sulla Random Forest\n",
    "grid_search = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    cv=skf,  # Usa StratifiedKFold\n",
    "    scoring='f1',  # Valutazione tramite AUC\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Esegui la ricerca\n",
    "grid_search.fit(X_tfidf, y)\n",
    "\n",
    "# Ottieni il miglior parametro e il miglior modello\n",
    "best_max_features = grid_search.best_params_['max_features']\n",
    "print(f\"Miglior valore per max_features: {best_max_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### CLASSIFICATION SENZA MAX FEATURES ############################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "#X = merged_dataset['testo_combinato_preprocessed'].fillna(\"\").astype(str)\n",
    "X = merged_dataset['testo_combinato_preprocessed']\n",
    "y = merged_dataset['positivi']\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "    \n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),  #VETTORIZZAZIONE SENZA MAX FEATURES\n",
    "        ('smote', SMOTE(random_state=42)), \n",
    "        ('classificazione', clf)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline to the data\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Trasforma i dati e ottieni la matrice TF-IDF\n",
    "    X_tfidf = pipeline.named_steps['tfidf'].transform(X)\n",
    "\n",
    "    # Ottieni la dimensione della matrice TF-IDF\n",
    "    num_samples, num_features = X_tfidf.shape\n",
    "    print(f\"Dimensione della matrice TF-IDF: {num_samples} campioni, {num_features} features\")\n",
    "\n",
    "    # Calcola le metriche usando la funzione\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "    \n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## CLASSIFICATION CON MAX FEATURES 5000 ###############################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "#X = merged_dataset['testo_combinato_preprocessed'].fillna(\"\").astype(str)\n",
    "X = merged_dataset['testo_combinato_preprocessed']\n",
    "y = merged_dataset['positivi']\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "    \n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000)),  #VETTORIZZAZIONE CON MAX FEATURES=5000\n",
    "        ('smote', SMOTE(random_state=42)), \n",
    "        ('classificazione', clf)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline to the data\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Trasforma i dati e ottieni la matrice TF-IDF\n",
    "    X_tfidf = pipeline.named_steps['tfidf'].transform(X)\n",
    "\n",
    "    # Ottieni la dimensione della matrice TF-IDF\n",
    "    num_samples, num_features = X_tfidf.shape\n",
    "    print(f\"Dimensione della matrice TF-IDF: {num_samples} campioni, {num_features} features\")\n",
    "\n",
    "    # Calcola le metriche usando la funzione\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg  = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "\n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Estrazione e interpretazione dei coefficienti (solo per la regressione logistica) ---\n",
    "if 'logisticregression' in clf_name.lower():  # Verifica che il classificatore sia una regressione logistica\n",
    "    model = pipeline.named_steps['classificazione']\n",
    "        \n",
    "    # Estrai il vocabolario del TfidfVectorizer\n",
    "    tfidf_vectorizer = pipeline.named_steps['tfidf']\n",
    "    vocab = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Estrai i coefficienti della regressione logistica\n",
    "    coefficients = model.coef_.flatten()  # Appiattisci per lavorare con un array 1D\n",
    "        \n",
    "    # Associa i coefficienti con le parole\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'word': vocab,\n",
    "        'coefficient': coefficients\n",
    "    })\n",
    "        \n",
    "    # Ordina le parole in base al valore assoluto del coefficiente (importanza)\n",
    "    feature_importance = feature_importance.reindex(feature_importance['coefficient'].abs().sort_values(ascending=False).index)\n",
    "        \n",
    "    # Visualizza le prime 10 parole più influenti (positivamente e negativamente)\n",
    "    print(\"\\nTop 10 feature più influenti (in base al coefficiente):\")\n",
    "    print(feature_importance.head(20))\n",
    "\n",
    "    print(\"\\nBottom 10 feature meno influenti (in base al coefficiente):\")\n",
    "    print(feature_importance.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SMOTE + UNDERSAMPLING CON MAX FEATURES ##########################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "#X = merged_dataset['testo_combinato_preprocessed'].fillna(\"\").astype(str)\n",
    "X = merged_dataset['testo_combinato_preprocessed']\n",
    "y = merged_dataset['positivi']\n",
    "\n",
    "# Stampa la distribuzione delle classi originale\n",
    "print(\"Distribuzione delle classi originale:\")\n",
    "print(np.unique(y, return_counts=True))\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "    \n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000)),  # Vettorizzazione con max_features=5000\n",
    "        ('smote', SMOTE(random_state=42, sampling_strategy= 0.1 )),  # Applica SMOTE prima per la classe minoritaria\n",
    "        ('undersample', RandomUnderSampler(sampling_strategy= 'auto', random_state=42)),  # Poi undersampling della classe maggioritaria\n",
    "        ('classificazione', clf)\n",
    "    ])\n",
    "\n",
    "    # Applica solo il vettorizzatore per ottenere la matrice TF-IDF e stamparne le dimensioni\n",
    "    X_tfidf = pipeline.named_steps['tfidf'].fit_transform(X)\n",
    "    num_samples, num_features = X_tfidf.shape\n",
    "    print(f\"Dimensione della matrice TF-IDF: {num_samples} campioni, {num_features} features\")\n",
    "\n",
    "    # Bilanciamento delle classi: applica SMOTE e undersampling separatamente e stampa la distribuzione delle classi\n",
    "    print(\"\\nDopo SMOTE:\")\n",
    "    X_smote, y_smote = SMOTE(random_state=42, sampling_strategy= 0.1 ).fit_resample(X_tfidf, y)\n",
    "    print(np.unique(y_smote, return_counts=True))\n",
    "\n",
    "    print(\"Dopo undersampling:\")\n",
    "    X_resampled, y_resampled = RandomUnderSampler(sampling_strategy= 'auto', random_state=42).fit_resample(X_smote, y_smote)\n",
    "    print(np.unique(y_resampled, return_counts=True))\n",
    "\n",
    "    \n",
    "    # Calcola le metriche usando la cross-validation\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "\n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
