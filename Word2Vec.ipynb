{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### carica dataset LDO 20-21 ############################ \n",
    "\n",
    "dataLDO2020 = pd.read_excel('/home/a.renda/to_move/LDO/filtrato_per_keyword/20-21_LDO_26K/LDO_20200101_20210101 pulito.ods', engine='odf')\n",
    "dataLDO2021=pd.read_excel('/home/a.renda/to_move/LDO/filtrato_per_keyword/20-21_LDO_26K/LDO_20210101_20220101 pulito.ods', engine='odf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra le righe che non contengono numeri (escludendo anche i NaN)\n",
    "dataLDO2021 = dataLDO2021[dataLDO2021['nosologico'].astype(str).str.contains(r'\\d')]\n",
    "#rimosse 212 righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nColumns LDO 20-21:\", dataLDO2020.columns)\n",
    "print(\"\\nColumns LDO 21-22:\", dataLDO2021.columns)\n",
    "print(\"\\nShape LDO 20-21:\", dataLDO2020.shape)\n",
    "print(\"\\nShape LDO 21-22:\", dataLDO2021.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## carica database filtrato ###############################\n",
    "\n",
    "databaseFiltrato=pd.read_csv('/home/a.renda/to_move/LDO/labeled/20-21_341/DatabaseFiltrato.csv', sep=';')\n",
    "print(databaseFiltrato.shape)\n",
    "print(databaseFiltrato.columns) # la prima colonna è solo un contatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra le righe che non contengono numeri (escludendo anche i NaN)\n",
    "databaseFiltrato = databaseFiltrato[databaseFiltrato['nosologico'].astype(str).str.contains(r'\\d')]\n",
    "\n",
    "#tolte 5 righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### filtra ldo 2020 ##########################\n",
    "\n",
    "# Converti la colonna 'nosologico' del secondo dataset in int\n",
    "databaseFiltrato['nosologico'] = pd.to_numeric(databaseFiltrato['nosologico'], errors='coerce')\n",
    "\n",
    "\n",
    "# Trova i nosologici comuni\n",
    "comuni2020 = dataLDO2020['nosologico'].isin(databaseFiltrato['nosologico'])\n",
    "\n",
    "# Filtra il primo dataset\n",
    "dataset_filtrato2020 = dataLDO2020[comuni2020]\n",
    "print(dataset_filtrato2020.columns)\n",
    "print(dataset_filtrato2020.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### filtra ldo 2021 ###########################\n",
    "\n",
    "# Trova i nosologici comuni\n",
    "comuni2021 = dataLDO2021['nosologico'].isin(databaseFiltrato['nosologico'])\n",
    "\n",
    "# Filtra il primo dataset\n",
    "dataset_filtrato2021 = dataLDO2021[comuni2021]\n",
    "print(dataset_filtrato2021.columns)\n",
    "print(dataset_filtrato2021.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## merge ldo2020 e ldo 2021 filtrati ###################################\n",
    "\n",
    "merged_dataset = pd.concat([dataset_filtrato2020, dataset_filtrato2021], ignore_index=True) # non ci sono duplicati tra i due dataset \n",
    "\n",
    "# Risultato finale\n",
    "print(\"\\nColumns merged dataset:\",merged_dataset.columns)\n",
    "print(\"\\nShape merged dataset:\",merged_dataset.shape)\n",
    "print(merged_dataset['testo'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## carica dataset con nosologici positivi #####################\n",
    "\n",
    "Positivi= pd.read_excel('/home/a.renda/to_move/LDO/labeled/20-21_341/NosologiciPositivi_341.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### aggiungere la colonna positivi #########################################\n",
    "\n",
    "# Convertire la colonna 'Nosologico' in numerico nel dataset NosologiciPositivi\n",
    "nosologici_positivi = pd.to_numeric(Positivi['NosologiciPositivi'], errors='coerce').dropna()\n",
    "\n",
    "# Creare la colonna 'positivi' nel DataFrame merged_dataset\n",
    "merged_dataset['positivi'] = merged_dataset['nosologico'].isin(nosologici_positivi).astype(int)\n",
    "\n",
    "\n",
    "# Contare quanti 1 e quanti 0 ci sono nella colonna 'positivi'\n",
    "count_positivi = merged_dataset['positivi'].value_counts()\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"\\nConteggio dei valori nella colonna 'positivi':\")\n",
    "print(f\"Numero di 1 (positivi): {count_positivi.get(1, 0)}\")\n",
    "print(f\"Numero di 0 (non positivi): {count_positivi.get(0, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unire parole e numeri in 'reparto' rimuovendo lo spazio e sostituendo con un trattino\n",
    "merged_dataset['reparto'] = merged_dataset['reparto'].str.replace(r'(\\w) (\\d)', r'\\1-\\2', regex=True)\n",
    "\n",
    "# Visualizza i risultati\n",
    "print(merged_dataset['reparto'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### pulisci il testo: risoluzione di errori di codifica, sostituzione caratteri speciali #######################\n",
    "import ftfy\n",
    "\n",
    "# Applica ftfy.fix_text() a tutte le colonne di testo nel dataset, gestendo i valori non testuali\n",
    "for col in merged_dataset.select_dtypes(include='object').columns:\n",
    "    merged_dataset[col] = merged_dataset[col].apply(lambda x: ftfy.fix_text(x) if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## PRE-PROCESSING ##########################\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Carica il modello SpaCy per l'italiano\n",
    "nlp = spacy.load(\"it_core_news_lg\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Lista delle colonne su cui applicare il preprocessing\n",
    "colonne_da_preprocessare = ['testo', 'motivo_ricovero', 'anamnesi', \n",
    "                             'esameobiettivo', 'terapiafarmaingresso', \n",
    "                             'decorso', 'laboratorio', 'interventi', \n",
    "                             'followup', 'terapie2', 'terapie3', \n",
    "                             'esami', 'reparto']  # Sostituisci con i nomi reali delle colonne\n",
    "\n",
    "# Funzione per pulire i token (inclusi numeri, punti e virgole)\n",
    "def clean_token(token):\n",
    "    \n",
    "    # Sostituisce tutti i caratteri non alfanumerici (inclusi simboli, punteggiatura, numeri, ecc.) con uno spazio.\n",
    "    cleaned_token = re.sub(r'[^a-zA-ZàèéìòùÀÈÉÌÒÙ]', ' ', token)\n",
    "    cleaned_token = re.sub(r'\\s+', ' ', cleaned_token).strip()  # Normalizza gli spazi multipli\n",
    "    \n",
    "    return cleaned_token\n",
    "\n",
    "# Funzione per tokenizzare e preprocessare il testo\n",
    "def preprocess_text(row):\n",
    "    if not isinstance(row, str):  # Verifica che il dato sia una stringa valida\n",
    "        return \"\"  # Restituisce una stringa vuota se non valido\n",
    "    \n",
    "    # Rimuove date nel formato 'dd/mm/yyyy' e 'dd/mm/yy'\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', '', row)\n",
    "    row = re.sub(r'\\d{1,2}/\\d{1,2}', '', row)  # Rimuove numeri separati da /\n",
    "       \n",
    "    # Aggiunge spazi tra numeri e lettere (es. \"800duloxetina\" -> \"800 duloxetina\")\n",
    "    row = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', row)\n",
    "    row = re.sub(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', row)\n",
    "\n",
    "    # Aggiunge spazi tra parole composte tipo \"vediAllegato\" -> \"vedi Allegato\"\n",
    "    row = re.sub(r'([a-zàèéìòù])([A-ZÀÈÉÌÒÙ])', r'\\1 \\2', row)\n",
    "\n",
    "    # normalizza  spazi (se ci sono più spazi consecutivi, vengono ridotti a uno solo) e rimuove  spazi all'inizio e alla fine della stringa\n",
    "    row = re.sub(r'[^\\w\\s]', ' ', row)  # Rimuove caratteri non alfanumerici e parentesi\n",
    "\n",
    "    # Tokenizza il testo con SpaCy\n",
    "    doc = nlp(row)\n",
    "    \n",
    "    # Filtra stopwords, punteggiatura e token senza embedding\n",
    "    tokens_puliti = [\n",
    "        clean_token(token.lemma_.lower())  # lemmatizzazione e pulisce il token\n",
    "        for token in doc\n",
    "        if not token.is_punct and not token.is_stop and len(token.text) > 1 #and token.text.isalpha() #per rimuovere token formati da una singola lettera\n",
    "    ]\n",
    "    \n",
    "    # Applica un filtro finale per rimuovere manualmente le lettere singole\n",
    "    tokens_puliti = [token for token in tokens_puliti if len(token) > 1]  # Assicura che tutte le parole siano > 1 carattere\n",
    "    \n",
    "    # Ricombina i token in una stringa\n",
    "    return \" \".join(tokens_puliti)\n",
    "\n",
    "# Applica il preprocessing per ciascuna colonna specificata\n",
    "for colonna in colonne_da_preprocessare:\n",
    "    nuova_colonna = f\"{colonna}_preprocessed\"  # Nome della nuova colonna\n",
    "    merged_dataset[nuova_colonna] = merged_dataset[colonna].apply(preprocess_text)\n",
    "\n",
    "# Visualizza i risultati per le nuove colonne preprocessate\n",
    "print(merged_dataset[[colonna for colonna in colonne_da_preprocessare] + \n",
    "                     [f\"{col}_preprocessed\" for col in colonne_da_preprocessare]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ DIMENSIONE VOCABOLARIO ############################\n",
    "# Calcola il vocabolario\n",
    "vocab_set = set()\n",
    "# Itera sulle prime 100 righe delle colonne preprocessate\n",
    "for colonna in colonne_da_preprocessare:\n",
    "    for testo in merged_dataset[f\"{colonna}_preprocessed\"]:  # Limita a 100 righe\n",
    "        if isinstance(testo, str):  # Assicurati che il testo non sia NaN\n",
    "            vocab_set.update(testo.split())\n",
    "\n",
    "# Calcola la dimensione del vocabolario\n",
    "vocabolario_dimensione = len(vocab_set)\n",
    "print(\"Dimensione del vocabolario:\", vocabolario_dimensione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### MEDIA NUMERO PAROLE COLONNE PRE-PROCESSATE #######################\n",
    "\n",
    "# Funzione per calcolare il numero di parole\n",
    "def count_words(text):\n",
    "    if isinstance(text, str):  # Verifica se il testo è una stringa\n",
    "        return len(text.split())  # Conta le parole\n",
    "    elif isinstance(text, (int, float)):  # Se è un numero\n",
    "        return 1  # Considera il numero come una parola\n",
    "    return 0  # Restituisce 0 se non è una stringa o un numero\n",
    "\n",
    "for colonna in colonne_da_preprocessare:\n",
    "    nuova_colonna = f\"{colonna}_preprocessed\"\n",
    "    word_counts = merged_dataset[nuova_colonna].apply(count_words)  # Conta le parole in ogni stringa\n",
    "    average_word_count = word_counts.mean()  # Calcola la lunghezza media\n",
    "    print(f\"Lunghezza media della colonna '{nuova_colonna}' in parole: {average_word_count:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## CLASSIFIERS #################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Definisci una lista di classificatori che vuoi provare\n",
    "classifiers = {\n",
    "    #'RandomForest': RandomForestClassifier(n_jobs=-1, max_depth=10, max_features=0.1, random_state=42),\n",
    "    #'LogisticRegression': LogisticRegression(random_state=42, max_iter=3000),\n",
    "    #'SVM': SVC(probability=True,random_state=42),\n",
    "    #'KNeighbors': KNeighborsClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    #'extremeGradientBoosting': XGBClassifier(learning_rate=0.1, random_state=42, n_jobs=-1, max_depth=6),\n",
    "    #'DecisionTree': DecisionTreeClassifier(max_depth=20, random_state=42),\n",
    "    #'GradientBoosting': GradientBoostingClassifier(learning_rate=0.1, min_samples_split=10, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## CROSS VALIDATION ########################\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def eval_cross_validation(pipeline, X, y, skf):\n",
    "    list_reports = []\n",
    "    list_auc = []  # Lista per raccogliere i valori di AUC\n",
    "    list_num_features = []  # Lista per raccogliere il numero di features per ogni fold\n",
    "\n",
    "    # Metriche aggregate per ogni classe\n",
    "    precision_sum = {}\n",
    "    recall_sum = {}\n",
    "    f1_sum = {}\n",
    "    support_sum = {}  # Per il calcolo del supporto medio\n",
    "\n",
    "    # Liste per calcolare deviazioni standard\n",
    "    precision_values = {}\n",
    "    recall_values = {}\n",
    "    f1_values = {}\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # Addestra il pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Previsioni e probabilità\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        y_pred_prob = pipeline.predict_proba(X_val)[:, 1]  # Probabilità della classe positiva\n",
    "\n",
    "        # Classification report per il fold\n",
    "        report = classification_report(y_val, y_pred, output_dict=True)\n",
    "        list_reports.append(report)\n",
    "\n",
    "        # AUC per il fold\n",
    "        auc = roc_auc_score(y_val, y_pred_prob)\n",
    "        list_auc.append(auc)\n",
    "\n",
    "        # Numero di features (fisso per embedding precalcolati)\n",
    "        num_features = X.shape[1]\n",
    "        list_num_features.append(num_features)\n",
    "\n",
    "        # Somma le metriche per ogni classe\n",
    "        for label, metrics in report.items():\n",
    "            if label not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "                precision_sum[label] = precision_sum.get(label, 0) + metrics[\"precision\"]\n",
    "                recall_sum[label] = recall_sum.get(label, 0) + metrics[\"recall\"]\n",
    "                f1_sum[label] = f1_sum.get(label, 0) + metrics[\"f1-score\"]\n",
    "                support_sum[label] = support_sum.get(label, 0) + metrics[\"support\"]\n",
    "\n",
    "                # Aggiungi i valori per la deviazione standard\n",
    "                precision_values[label] = precision_values.get(label, []) + [metrics[\"precision\"]]\n",
    "                recall_values[label] = recall_values.get(label, []) + [metrics[\"recall\"]]\n",
    "                f1_values[label] = f1_values.get(label, []) + [metrics[\"f1-score\"]]\n",
    "\n",
    "    # Calcola le medie delle metriche\n",
    "    num_folds = skf.get_n_splits()\n",
    "    precision_avg = {label: precision_sum[label] / num_folds for label in precision_sum}\n",
    "    recall_avg = {label: recall_sum[label] / num_folds for label in recall_sum}\n",
    "    f1_avg_per_class = {label: f1_sum[label] / num_folds for label in f1_sum}\n",
    "    support_avg = {label: support_sum[label] / num_folds for label in support_sum}\n",
    "\n",
    "    # Calcola le deviazioni standard\n",
    "    precision_std = {label: np.std(precision_values[label]) for label in precision_values}\n",
    "    recall_std = {label: np.std(recall_values[label]) for label in recall_values}\n",
    "    f1_std = {label: np.std(f1_values[label]) for label in f1_values}\n",
    "\n",
    "    # Media di AUC e numero di features\n",
    "    auc_avg = np.mean(list_auc)\n",
    "    num_features_avg = np.mean(list_num_features)\n",
    "\n",
    "    # Crea un DataFrame riassuntivo\n",
    "    df_avg = pd.DataFrame({\n",
    "        \"Precision\": precision_avg,\n",
    "        \"Recall\": recall_avg,\n",
    "        \"F1-Score\": f1_avg_per_class,\n",
    "        \"Support Avg\": support_avg,  # Supporto medio\n",
    "        \"Precision Std\": precision_std,\n",
    "        \"Recall Std\": recall_std,\n",
    "        \"F1-Score Std\": f1_std,\n",
    "    })\n",
    "\n",
    "    return df_avg, auc_avg, f1_avg_per_class, num_features_avg\n",
    "\n",
    "\n",
    "# Configura StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download it_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### WORD2VEC con embedding precalcolati spacy (senza vettore di zeri + counter oov) #################\n",
    "\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_embeddings_parallel(texts, nosologici, nlp, batch_size=1000, n_process=-1, max_oov_display=50):\n",
    "    print(\"Calcolo degli embedding in corso...\")\n",
    "\n",
    "    # Inizializza contatori e insiemi\n",
    "    oov_words_counter = Counter()  # Contatore per parole OOV\n",
    "    valid_words_unique = set()  # Parole valide uniche\n",
    "    oov_per_doc = []  # Numero di parole OOV per documento\n",
    "    oov_details = []  # Dettagli OOV per documento (numero di OOV e testo originale, nosologico)\n",
    "\n",
    "    # Elaborazione dei testi in batch\n",
    "    docs = nlp.pipe(texts, batch_size=batch_size, n_process=n_process)\n",
    "    embeddings = []\n",
    "\n",
    "    for idx, doc in enumerate(docs):\n",
    "        doc_embedding = []\n",
    "        doc_oov = set()  # Parole OOV uniche per questo documento\n",
    "\n",
    "        for token in doc:\n",
    "            if not token.has_vector or np.all(token.vector == 0):\n",
    "                if token.text.strip():\n",
    "                    oov_words_counter[token.text] += 1\n",
    "                    doc_oov.add(token.text)\n",
    "            else:\n",
    "                valid_words_unique.add(token.text)\n",
    "                doc_embedding.append(token.vector)\n",
    "\n",
    "        # Calcola embedding medio del documento\n",
    "        if doc_embedding:\n",
    "            embeddings.append(np.mean(doc_embedding, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(nlp.vocab.vectors_length))  # Fallback: vettore zero\n",
    "\n",
    "        oov_per_doc.append(len(doc_oov))\n",
    "        oov_details.append((len(doc_oov), texts[idx], nosologici[idx]))\n",
    "\n",
    "    # Calcolo statistiche\n",
    "    total_unique_words = len(valid_words_unique.union(oov_words_counter.keys()))\n",
    "    oov_percentage_unique = (len(oov_words_counter.keys()) / total_unique_words) * 100\n",
    "\n",
    "    print(f\"Totale parole valide uniche: {len(valid_words_unique)}\")\n",
    "    print(f\"Totale parole OOV uniche: {len(oov_words_counter.keys())}\")\n",
    "    print(f\"Totale parole uniche nel dataset (OOV + valide): {total_unique_words}\")\n",
    "    print(f\"Percentuale di parole OOV rispetto al totale di parole uniche: {oov_percentage_unique:.2f}%\")\n",
    "\n",
    "    # Mostra prime parole OOV\n",
    "    print(\"\\nPrime 50 parole OOV uniche ordinate per frequenza:\")\n",
    "    for i, (word, count) in enumerate(oov_words_counter.most_common(max_oov_display)):\n",
    "        print(f\"{i+1}. {word}: {count}\")\n",
    "\n",
    "    print(\"Calcolo degli embedding completato.\")\n",
    "\n",
    "    return np.array(embeddings), oov_words_counter, valid_words_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### EMBEDDING MULTI COLONNA ##################################\n",
    "\n",
    "def compute_embeddings_multiple_columns(column_names, nosologici, nlp, batch_size=1000, n_process=-1):\n",
    "    combined_embeddings = None\n",
    "    global_oov_counter = Counter()\n",
    "    global_valid_words = set()\n",
    "    column_oov_counts = {}  # Per salvare il conteggio OOV per ogni colonna\n",
    "\n",
    "\n",
    "    for col_idx, column_name in enumerate(column_names):\n",
    "        print(f\"Elaborazione della colonna '{column_name}' ({col_idx + 1}/{len(column_names)})...\")\n",
    "\n",
    "        # Estrai testi dalla colonna\n",
    "        texts = merged_dataset[column_name].fillna(\"\").tolist()\n",
    "\n",
    "        # Calcola embedding per la colonna\n",
    "        embeddings, oov_words_counter, valid_words_unique = compute_embeddings_parallel(\n",
    "            texts, nosologici, nlp, batch_size, n_process\n",
    "        )\n",
    "\n",
    "        # Calcola il numero di OOV per ogni documento in questa colonna\n",
    "        oov_per_doc = []\n",
    "        for text in texts:\n",
    "            oov_count = len([word for word in text.split() if word in oov_words_counter])\n",
    "            oov_per_doc.append(oov_count)\n",
    "\n",
    "        # Calcola la media degli OOV per la colonna\n",
    "        column_oov_counts[column_name] = oov_per_doc\n",
    "\n",
    "        # Converti in array numpy e verifica la forma\n",
    "        embeddings = np.array(embeddings)\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(-1, 1)\n",
    "\n",
    "        # Combina gli embedding\n",
    "        if combined_embeddings is None:\n",
    "            combined_embeddings = embeddings\n",
    "        else:\n",
    "            combined_embeddings = np.hstack((combined_embeddings, embeddings))\n",
    "\n",
    "        # Aggiorna statistiche globali\n",
    "        global_oov_counter.update(oov_words_counter)\n",
    "        global_valid_words.update(valid_words_unique)\n",
    "\n",
    "    # Statistiche globali\n",
    "    total_unique_words = len(global_valid_words.union(global_oov_counter.keys()))\n",
    "    oov_percentage_unique = (len(global_oov_counter.keys()) / total_unique_words) * 100\n",
    "\n",
    "    print(\"\\n### Statistiche globali sugli embedding combinati ###\")\n",
    "    print(f\"Totale parole valide uniche (tutte le colonne): {len(global_valid_words)}\")\n",
    "    print(f\"Totale parole OOV uniche (tutte le colonne): {len(global_oov_counter.keys())}\")\n",
    "    print(f\"Totale parole uniche nel dataset (valide + OOV): {total_unique_words}\")\n",
    "    print(f\"Percentuale di parole OOV rispetto al totale di parole uniche: {oov_percentage_unique:.2f}%\")\n",
    "\n",
    "    # Stampa le prime 50 OOV globali\n",
    "    print(\"\\nPrime 50 parole OOV uniche ordinate per frequenza (globali):\")\n",
    "    for i, (word, count) in enumerate(global_oov_counter.most_common(50)):\n",
    "        print(f\"{i+1}. {word}: {count}\")\n",
    "\n",
    "    # Calcolare la media degli OOV per ogni colonna\n",
    "    column_oov_averages = {col: np.mean(oov_counts) for col, oov_counts in column_oov_counts.items()}\n",
    "\n",
    "    # Ordinare le colonne in base al numero medio di OOV\n",
    "    sorted_columns = sorted(column_oov_averages.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Stampa le colonne ordinate in base alla media degli OOV\n",
    "    print(\"\\nOrdine delle colonne in base al numero medio di OOV (decrescente):\")\n",
    "    for i, (column_name, avg_oov) in enumerate(sorted_columns):\n",
    "        print(f\"{i + 1}. Colonna: '{column_name}' | OOV medio: {avg_oov:.2f}\")\n",
    "\n",
    "    # Crea il grafico a barre con il numero medio di OOV per colonna\n",
    "    column_names_sorted = [x[0] for x in sorted_columns]\n",
    "    avg_oov_values = [x[1] for x in sorted_columns]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(column_names_sorted, avg_oov_values, color='skyblue')\n",
    "    plt.xlabel('Numero Medio di OOV')\n",
    "    plt.ylabel('Colonne')\n",
    "    plt.title('Numero Medio di OOV per Colonna')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.show()\n",
    "\n",
    "    # Verifica della dimensione finale degli embedding combinati\n",
    "    combined_embeddings = np.array(combined_embeddings)\n",
    "    print(f\"\\n### Dimensione degli embedding combinati ###\")\n",
    "    print(f\"Shape (n_righe, n_colonne): {combined_embeddings.shape}\")\n",
    "    print(f\"n_righe: {combined_embeddings.shape[0]} (dovrebbe essere uguale al numero di righe del dataset: {len(merged_dataset)})\")\n",
    "    print(f\"n_colonne: {combined_embeddings.shape[1]} (dovrebbe essere 300 x {len(column_names)} = {300 * len(column_names)})\")\n",
    "\n",
    "    print(\"Calcolo degli embedding combinati completato.\")\n",
    "\n",
    "    return combined_embeddings\n",
    "\n",
    "\n",
    "# Elenco delle colonne di testo\n",
    "text_columns = [\n",
    "    'testo_preprocessed', 'motivo_ricovero_preprocessed', 'anamnesi_preprocessed', \n",
    "               'esameobiettivo_preprocessed', 'terapiafarmaingresso_preprocessed', \n",
    "               'decorso_preprocessed', 'laboratorio_preprocessed', 'interventi_preprocessed', \n",
    "               'followup_preprocessed', 'terapie2_preprocessed', 'terapie3_preprocessed', \n",
    "               'esami_preprocessed', 'reparto_preprocessed'\n",
    "]\n",
    "\n",
    "y = merged_dataset['positivi']\n",
    "nosologici = merged_dataset['nosologico'].tolist()  # Lista degli identificativi (colonna 'nosologico')\n",
    "\n",
    "# Calcolo degli embedding combinati\n",
    "X_embeddings_combined = compute_embeddings_multiple_columns(text_columns, nosologici, nlp)\n",
    "\n",
    "# Salva gli embedding combinati\n",
    "np.save('X_embeddings_combined.npy', X_embeddings_combined)\n",
    "\n",
    "# Per ricaricare in futuro\n",
    "# X_embeddings_combined = np.load('X_embeddings_combined.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### NO SMOTE ###################################\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "\n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([('classificazione', clf)])\n",
    "\n",
    "    # Usa gli embedding precalcolati\n",
    "    X = X_embeddings_combined\n",
    "\n",
    "    # Fit della pipeline\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Calcola le metriche usando la funzione (modifica per adattare alla tua funzione eval_cross_validation)\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "\n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### SMOTE #######################################\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "\n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([('smote', SMOTE(random_state=42)),('classificazione', clf)])\n",
    "\n",
    "    # Usa gli embedding precalcolati\n",
    "    X = X_embeddings_combined\n",
    "\n",
    "    # Fit della pipeline\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Calcola le metriche usando la funzione (modifica per adattare alla tua funzione eval_cross_validation)\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "\n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### SMOTE + UNDERSAMLING #######################################\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Esegui la cross-validation per ogni classificatore\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n### Modello: {clf_name} ###\")\n",
    "\n",
    "    # Crea la pipeline per il classificatore corrente\n",
    "    pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42, sampling_strategy=0.6)),  # Applica SMOTE fino al 60% della classe maggioritaria\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy=1.0, random_state=42)),\n",
    "    ('classificazione', clf)])\n",
    "\n",
    "    # Usa gli embedding precalcolati\n",
    "    X = X_embeddings_combined\n",
    "\n",
    "    # Fit della pipeline\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Calcola le metriche usando la funzione (modifica per adattare alla tua funzione eval_cross_validation)\n",
    "    df_avg, auc_avg, f1_avg_per_class, num_features_avg = eval_cross_validation(pipeline, X, y, skf)\n",
    "\n",
    "    # Stampa i risultati\n",
    "    print(\"Classification report mediato:\")\n",
    "    print(df_avg)\n",
    "    print(f\"AUC medio: {auc_avg:.4f}\")\n",
    "    print(f\"Numero medio di features: {num_features_avg:.2f}\")\n",
    "\n",
    "    # Previsioni su tutto il dataset usando cross_val_predict\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "    # Visualizza la matrice di confusione\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "    plt.title(f\"Matrice di Confusione - {clf_name}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
